{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the randomized experiment (RCT/ AB test)\n",
    "\n",
    "reminder:\n",
    "\n",
    "correlation (more generally, *association*) is not causation\n",
    "\n",
    "...unless...maybe.. it is.\n",
    "\n",
    "we have a treatment/intervention $ X \\in \\{0,1\\}$\n",
    "\n",
    "and we have an outcome variable $ Y $\n",
    "\n",
    "`avg(Y | X = 1) - avg(Y | X = 0) = avg treatment effect (on the treated) + bias`\n",
    "\n",
    "for now, let's give hand-wavy definitions:\n",
    "\n",
    "treatment effect = \"avg difference in $Y$ when the treatment is given vs when it is not given\"\n",
    "\n",
    "bias = \"avg difference in $Y$ if noone got the treatment\"\n",
    "\n",
    "the nice thing about AB tests, is that they are designed to eliminate bias\n",
    "\n",
    "how?\n",
    "\n",
    "bias can be eliminated through random assignment of $X$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>version</th>\n",
       "      <th>sum_gamerounds</th>\n",
       "      <th>retention_1</th>\n",
       "      <th>retention_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>gate_30</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>337</td>\n",
       "      <td>gate_30</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>377</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>165</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  version  sum_gamerounds  retention_1  retention_7\n",
       "0     116  gate_30               3        False        False\n",
       "1     337  gate_30              38         True        False\n",
       "2     377  gate_40             165         True        False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cats = pd.read_csv('../cookie_cats.csv')\n",
    "\n",
    "# mobile gaming dataset\n",
    "# quite large: tens of thousands of observations\n",
    "\n",
    "# we have to make up a story about the experimental set up:\n",
    "\n",
    "# we have a mobile game (a game you play on your cell phone)\n",
    "# intervention/experimental condition/X - \"the thing that's different between the two groups\"\n",
    "# group A sees the gate at level 30\n",
    "# group B sees the gate at level 40\n",
    "# we measure 3 outcomes as a function of the intervention:\n",
    "# total number of games played from the moment the experiment was launched to 14 days after.\n",
    "# and retention .. after 1 day and after 7 days.\n",
    "\n",
    "# let's assume prior to the experiment ALL players saw the gate at level 30\n",
    "# that would mean the experimental condition is \"player sees the gate at level 40\"\n",
    "\n",
    "cats.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quick review\n",
    "\n",
    "pvalue what does it mean?\n",
    "\n",
    "probability of type 1 error, i.e. false positive rate, i.e. probability of rejecting the null hypothesis when you should NOT have\n",
    "\n",
    "pvalue = \"in a world where there's no difference between group A and B, we should expect to see data that looks like this pvalue percentage of the time\"\n",
    "\n",
    "if you do 1,000,000 hypothesis tests and get 1,000,000 pvalues of .0499999 (which leads you to reject the null every time) you will have 50,000 false positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=0.8910426211362967, pvalue=0.37290868247405207, df=90187.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomization - we have to take it for granted here.\n",
    "# what data would we need to do the random assignment ourselves\n",
    "# we want to make sure that \"on average\" the players in group A and B \n",
    "# had the same level of engagement before the experiment\n",
    "\n",
    "# what hypothesis test should we use\n",
    "# t-test, specifically two-sample unpaired independent t-test\n",
    "\n",
    "# null hypothesis: mean(sum of game rounds for group A) - mean(sum of game rounds for group B) = 0\n",
    "# alternative hypothesis: ~null hypothesis \n",
    "# mean(sum of game rounds for group A) - mean(sum of game rounds for group B) != 0\n",
    "\n",
    "# significance threshold\n",
    "# most people arbitrarily use .05\n",
    "# if p(false positive) < .05 we will decide to kind of believe the result\n",
    "\n",
    "gate_30 = cats.loc[cats['version'] == \"gate_30\",\"sum_gamerounds\"] # group A\n",
    "gate_40 = cats.loc[cats['version'] == \"gate_40\",\"sum_gamerounds\"] # group B\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "ttest_ind(gate_30,gate_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpretation:\n",
    "\n",
    "we fail to reject the null hypothesis\n",
    "\n",
    "let's check our intuition about hypothesis testing\n",
    "\n",
    "we've done this experiment...and now we want to explain where the variability in the data comes from, and there's really only three options:\n",
    "\n",
    "**option 1**: all the variability is due to the systematic effect of the treatment\n",
    "\n",
    "`gate_30_gr = (120, 120, 120, 120, ....)`\n",
    "\n",
    "`gate_40_gr = (119, 119, 119, 119, ....)`\n",
    "\n",
    "as you can see, this is highly unlikely to be the case.\n",
    "\n",
    "**option 2**: all the variability is due to randomness/bias (noise) \n",
    "\n",
    "**^^^ when we do a hypothesis test, we're testing this ^^^**\n",
    "\n",
    "**option 3:** the variability is some combination of systematic effect and noise\n",
    "\n",
    "**^^^ when we reject the null, we are choosing to believe this ^^^**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002\n"
     ]
    }
   ],
   "source": [
    "# next\n",
    "# 7 day retention (rate, category) ~ version (categorical (gate_30,40))\n",
    "# proportions z test\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "# prep the data\n",
    "retention_gate_30 = cats.loc[cats['version'] == \"gate_30\",\"retention_7\"] # group A\n",
    "retention_gate_40 = cats.loc[cats['version'] == \"gate_40\",\"retention_7\"] # group B\n",
    "count = np.array([retention_gate_30.sum(),retention_gate_40.sum()])\n",
    "nobs = np.array([retention_gate_30.shape[0],retention_gate_40.shape[0]])\n",
    "# run the test\n",
    "# wait a sec\n",
    "# what are the null/alt hypotheses\n",
    "# null: retention rate gate_30 = retention_rate gate_40\n",
    "# alt:  retention rate gate_30 != retention_rate gate_40 (or just: ~null)\n",
    "\n",
    "_, pval = proportions_ztest(count, nobs)\n",
    "# print the result\n",
    "print(f'{round(pval,3)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gate_30</th>\n",
       "      <td>8502</td>\n",
       "      <td>0.190201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gate_40</th>\n",
       "      <td>8279</td>\n",
       "      <td>0.182000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sum      mean\n",
       "version                \n",
       "gate_30  8502  0.190201\n",
       "gate_40  8279  0.182000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the test only hints at the strength and direction of the effect\n",
    "# we need to take a closer look\n",
    "cats.groupby('version')['retention_7'].agg(['sum','mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there's usually more than one way to answer the same question\n",
    "\n",
    "statistical methods are like little robots - some are designed for a single purpose\n",
    "\n",
    "for example, we used a t-test to evaluate sum_gamerounds (numeric) ~ version (categorical)\n",
    "\n",
    "are there other tools that we could apply. what about a regression?\n",
    "\n",
    "`avg(sum_gamerounds | version) = beta0 + beta_version*version{1,0}`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

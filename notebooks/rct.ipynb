{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first approach to causal inference: the randomized experiment (RCT/ AB test)\n",
    "\n",
    "reminder:\n",
    "\n",
    "correlation (more generally, *association*) is not causation\n",
    "\n",
    "...unless...maybe.. it is.\n",
    "\n",
    "we have a treatment/intervention $ T \\in \\{0,1\\}$\n",
    "\n",
    "and we have an outcome variable $ Y $\n",
    "\n",
    "`avg(Y | T = 1) - avg(Y | T = 0)`\n",
    "\n",
    "for now\n",
    "\n",
    "treatment effect = \"the difference between Y when the treatment is given vs when it is not given\"\n",
    "\n",
    "bias = \"difference between Y for people who got the treatment vs didn't get the treatment in the case where NOONE got the treatment - ARE THE TWO GROUPS COMPARABLE\"\n",
    "\n",
    "the nice thing about AB tests, is that they are designed to eliminate bias\n",
    "\n",
    "how?\n",
    "\n",
    "bias can be eliminated through randomization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>version</th>\n",
       "      <th>sum_gamerounds</th>\n",
       "      <th>retention_1</th>\n",
       "      <th>retention_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>gate_30</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>337</td>\n",
       "      <td>gate_30</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>377</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>165</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>483</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>488</td>\n",
       "      <td>gate_40</td>\n",
       "      <td>179</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  version  sum_gamerounds  retention_1  retention_7\n",
       "0     116  gate_30               3        False        False\n",
       "1     337  gate_30              38         True        False\n",
       "2     377  gate_40             165         True        False\n",
       "3     483  gate_40               1        False        False\n",
       "4     488  gate_40             179         True         True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cats = pd.read_csv('cookie_cats.csv')\n",
    "cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomization - we have to take it for granted here.\n",
    "# what data would we need to do the random assignment ourselves\n",
    "# we want to make sure that \"on average\" the players in group A and B \n",
    "# had the same level of engagement before the experiment starts\n",
    "\n",
    "# 3 outcome variables\n",
    "# sum_gamerounds (numeric, total number of games played for the first 14 days after the install)\n",
    "# retention_1 did the player come back yes/no 1/0 true/false one day after installing\n",
    "# retention_7 ' seven after installing.\n",
    "\n",
    "# statistics / hypothesis testing\n",
    "\n",
    "# comparing sum of game rounds between group A and B.\n",
    "\n",
    "# null hypothesis for most hypothesis tests is that the data is not different across the groups\n",
    "\n",
    "# what hypothesis test should we use\n",
    "# a numeric variable, and 2 groups/samples we are assuming the samples are independent\n",
    "# t-test, specifically two-sample unpaired independent t-test\n",
    "\n",
    "# null hypothesis: mean(sum of game rounds for group A) - mean(sum of game rounds for group B) = 0\n",
    "# alternative hypothesis: ~null hypothesis \n",
    "# mean(sum of game rounds for group A) - mean(sum of game rounds for group B) != 0\n",
    "\n",
    "gate_30 = cats.loc[cats['version'] == \"gate_30\",\"sum_gamerounds\"] # group A\n",
    "gate_40 = cats.loc[cats['version'] == \"gate_40\",\"sum_gamerounds\"] # group B\n",
    "\n",
    "# \"we put the gate at level 40 instead of level 30 - does it make a difference in total gamerounds played\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=0.8910426211362967, pvalue=0.37290868247405207, df=90187.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "ttest_ind(gate_30,gate_40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pvalue - what does it mean?\n",
    "\n",
    "probability of type 1 error\n",
    "\n",
    "type 1 error - \"rejecting the null hypothesis when you should NOT have\"\n",
    "type 1 error - false positive\n",
    "\n",
    "pvalue = \"in a world where there's no difference between group A and B, we would see this data/this result pvalue percentage of the time\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we did this experiment and there's 3 possible explanations for the data\n",
    "\n",
    "- all the differences we see are due to the systematic effect of the treatment\n",
    "\n",
    "this is very unlikely AND it would be immediately obvious\n",
    "\n",
    "`sum_gamerounds_A = (100, 100, 100, 100, 100, ...)`\n",
    "\n",
    "`sum_gamerounds_B = (120, 120, 120, 120, 120, ...)`\n",
    "\n",
    "- all the differences we see are due to randomness/noise <- we are testing this when we look at the pvalue\n",
    "- some combination of systematic effect and randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retention_gate_30 = cats.loc[cats['version'] == \"gate_30\",\"retention_7\"] # group A\n",
    "retention_gate_40 = cats.loc[cats['version'] == \"gate_40\",\"retention_7\"] # group B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8502"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002\n"
     ]
    }
   ],
   "source": [
    "# proportions z test\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "count = np.array([retention_gate_30.sum(),retention_gate_40.sum()])\n",
    "nobs = np.array([retention_gate_30.shape[0],retention_gate_40.shape[0]])\n",
    "stat, pval = proportions_ztest(count, nobs)\n",
    "print('{0:0.3f}'.format(pval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gate_30</th>\n",
       "      <td>8502</td>\n",
       "      <td>0.190201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gate_40</th>\n",
       "      <td>8279</td>\n",
       "      <td>0.182000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sum      mean\n",
       "version                \n",
       "gate_30  8502  0.190201\n",
       "gate_40  8279  0.182000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.groupby('version')['retention_7'].agg(['sum','mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's always more than one way to answer the same question\n",
    "\n",
    "# sum_gamerounds (numeric) ~ version (categorical)\n",
    "# we used a t-test for this\n",
    "# is there other tools????\n",
    "# sum_gamerounds = beta0 + beta_version*version{1,0}\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "cats['version_binary'] = np.where(cats['version'] == 'gate_30',1,0)\n",
    "catsX = cats[['version_binary']]\n",
    "x = sm.add_constant(catsX)\n",
    "y = cats['sum_gamerounds']\n",
    "\n",
    "mod = sm.OLS(y,x)\n",
    "\n",
    "res = mod.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          3\n",
       "1         38\n",
       "2        165\n",
       "3          1\n",
       "4        179\n",
       "        ... \n",
       "90184     97\n",
       "90185     30\n",
       "90186     28\n",
       "90187     51\n",
       "90188     16\n",
       "Name: sum_gamerounds, Length: 90189, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (90189,2) and (90189,2) not aligned: 2 (dim 1) != 90189 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res\u001b[39m.\u001b[39;49msummary()\n",
      "File \u001b[0;32m~/mambaforge/envs/basic/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:2774\u001b[0m, in \u001b[0;36mRegressionResults.summary\u001b[0;34m(self, yname, xname, title, alpha, slim)\u001b[0m\n\u001b[1;32m   2770\u001b[0m     top_left\u001b[39m.\u001b[39mappend((\u001b[39m'\u001b[39m\u001b[39mCovariance Type:\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcov_type]))\n\u001b[1;32m   2772\u001b[0m rsquared_type \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m (uncentered)\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2773\u001b[0m top_right \u001b[39m=\u001b[39m [(\u001b[39m'\u001b[39m\u001b[39mR-squared\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m rsquared_type \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m-> 2774\u001b[0m               [\u001b[39m\"\u001b[39m\u001b[39m%#8.3f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrsquared]),\n\u001b[1;32m   2775\u001b[0m              (\u001b[39m'\u001b[39m\u001b[39mAdj. R-squared\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m rsquared_type \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2776\u001b[0m               [\u001b[39m\"\u001b[39m\u001b[39m%#8.3f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrsquared_adj]),\n\u001b[1;32m   2777\u001b[0m              (\u001b[39m'\u001b[39m\u001b[39mF-statistic:\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39m%#8.4g\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfvalue]),\n\u001b[1;32m   2778\u001b[0m              (\u001b[39m'\u001b[39m\u001b[39mProb (F-statistic):\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39m%#6.3g\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_pvalue]),\n\u001b[1;32m   2779\u001b[0m              (\u001b[39m'\u001b[39m\u001b[39mLog-Likelihood:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   2780\u001b[0m              (\u001b[39m'\u001b[39m\u001b[39mAIC:\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39m%#8.4g\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maic]),\n\u001b[1;32m   2781\u001b[0m              (\u001b[39m'\u001b[39m\u001b[39mBIC:\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39m%#8.4g\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbic])\n\u001b[1;32m   2782\u001b[0m              ]\n\u001b[1;32m   2784\u001b[0m \u001b[39mif\u001b[39;00m slim:\n\u001b[1;32m   2785\u001b[0m     slimlist \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mDep. Variable:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mModel:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNo. Observations:\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2786\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mCovariance Type:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mR-squared:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAdj. R-squared:\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2787\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mF-statistic:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mProb (F-statistic):\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/basic/lib/python3.11/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/basic/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1783\u001b[0m, in \u001b[0;36mRegressionResults.rsquared\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1781\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssr\u001b[39m/\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcentered_tss\n\u001b[1;32m   1782\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1783\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssr\u001b[39m/\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muncentered_tss\n",
      "File \u001b[0;32m~/mambaforge/envs/basic/lib/python3.11/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/basic/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1722\u001b[0m, in \u001b[0;36mRegressionResults.ssr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Sum of squared (whitened) residuals.\"\"\"\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m wresid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwresid\n\u001b[0;32m-> 1722\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mdot(wresid, wresid)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (90189,2) and (90189,2) not aligned: 2 (dim 1) != 90189 (dim 0)"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "mod = LinearRegression()\n",
    "mod.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,) (32, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load modules and data\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "spector_data = sm.datasets.spector.load()\n",
    "\n",
    "spector_data.exog = sm.add_constant(spector_data.exog, prepend=False)\n",
    "\n",
    "# Fit and summarize OLS model\n",
    "print(spector_data.endog.shape, spector_data.exog.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90189, 2) (90189,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
